description:
  name: $(WORKFLOW_NAME)
  description: |-
   Design Optimization Template
   To use,
   1. Specify the first three variables here (N_DIMS, TEST_FUNCTION, DEBUG)
   2. Run the template_config file in current directory using `python template_config.py`
   3. Merlin run as usual (merlin run optimization.yaml)
   * You could remove any of the specified variables and
      replace with your own variables


env:
  variables:
    # These three are necessary for template_config.py
    N_DIMS: 2
    TEST_FUNCTION: "rosen"
    DEBUG: 0

    WORKFLOW_NAME: wf_optimization
    SCRIPTS: $(SPECROOT)/scripts

    METHOD: 'trust-constr'
    EMAIL_ADDRESS: "NONE"  #enter your email address here, or override this with --vars
    RUN_TYPE: "run --local"

    ITER: 1
    MAX_ITER: "{{ max_iter|default(2, true) }}"

    BOUNDS_X: "{{ bounds_x }}"
    UNCERTS_X: "{{ uncerts_x }}"

    # pick_new_inputs step
    SEARCH_SCALE: 0.30
    N_SAMPLES: "{{ n_samples|default(3, true)  }}" # Number of new samples per iteration around the predicted new point
    N_EXPLOIT: "{{ n_exploit|default(3, true)  }}" # Number of new samples per iteration around the current best
    N_SAMPLES_LINE: "{{ n_samples_line|default(3, true)  }}" # Number between predicted best and current best
    N_SAMPLES_START: "{{ n_samples_start|default(12, true)  }}" # Number to initialize


study:
    - name: run_simulation
      description: Run the desired simulation
      run:
        cmd: |-
          python3 $(SCRIPTS)/test_functions.py -function $(TEST_FUNCTION) -ID "$(ITER)/$(MERLIN_SAMPLE_ID)" -inputs {% for column_label in column_labels %} $({{ column_label }}) {% endfor %}

        cores per task: 1
        nodes: 1
        procs: 1
        task_queue: simulation

    - name: collector
      description: Collect the results into a single file and make an npz of some features
      run:
        cmd: |-
          python3 $(SCRIPTS)/collector.py -sim_dirs "$(run_simulation.workspace)/$(MERLIN_GLOB_PATH)"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [run_simulation_*]
        task_queue: simulation_postprocess

    - name: clean_up_simulation
      description: Cleans up the merlin sample paths of the run_simulation step
      run:
        cmd: |-
          rm -rf $(run_simulation.workspace)/$(MERLIN_SAMPLE_PATH)

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [collector]
        task_queue: simulation_postprocess

    - name: learner
      description: Train an ML model on the simulation
      run:
        cmd: |-
          temp=1
          if [ $(ITER) -ge "$temp" ] ; then
              echo "Copying the npz file from previous iteration"
              cp ../../../learner/all_iter_results.npz .
          fi

          python3 $(SCRIPTS)/learner.py -collector_dir "$(collector.workspace)"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [clean_up_simulation]
        task_queue: learner

    - name: optimizer
      description: Optimizer
      run:
        cmd: |-
          python3 $(SCRIPTS)/optimizer.py -learner_dir "$(learner.workspace)" -bounds "$(BOUNDS_X)" -input_uncerts "$(UNCERTS_X)" -method "$(METHOD)"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [collector, learner]
        task_queue: learner

    - name: pick_new_inputs
      description: Picking new simulations to run in the next iteration
      run:
        cmd: |-
          spellbook make-samples -dims $(N_DIMS) -x0 $(optimizer.workspace)/optimum.npy -x1 $(optimizer.workspace)/old_best.npy -n_line $(N_SAMPLES_LINE) -scale_factor $(SEARCH_SCALE) -scale "$(BOUNDS_X)" -n $(N_SAMPLES) -sample_type lhd -outfile new_explore_samples.npy --hard-bounds
          spellbook make-samples -dims $(N_DIMS) -x0 $(optimizer.workspace)/optimum.npy -scale_factor 0.05 -scale "$(BOUNDS_X)" -sample_type star -outfile new_explore_star_samples.npy --hard-bounds
          # Add points near current best too
          spellbook make-samples -dims $(N_DIMS) -x0 $(optimizer.workspace)/old_best.npy -scale_factor $(SEARCH_SCALE) -scale "$(BOUNDS_X)" -n $(N_EXPLOIT) -sample_type lhd -outfile new_exploit_samples.npy --hard-bounds

          # combine them
          python3 -c "import numpy as np; np.save('new_samples.npy',np.vstack((np.load('new_explore_samples.npy'),np.load('new_exploit_samples.npy'),np.load('new_explore_star_samples.npy'))))"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [optimizer]
        task_queue: learner

    - name: visualizer
      description: Either launches new simulations or iterated with inputs from previous step
      run:
        cmd: |-
          # Add an if statment to make sure it is rosenbrock function and 2D
          python3 $(SCRIPTS)/visualizer.py -study_dir $(MERLIN_WORKSPACE)
        cores per task: 1
        nodes: 1
        procs: 1
        depends: [pick_new_inputs]
        task_queue: learner

    - name: iterate
      description: Either launches new simulations or iterated with inputs from previous step
      run:
        cmd: |-
          mv $(optimizer.workspace)/optimization_results.json optimization_results_iter_$(ITER).json
          mv $(visualizer.workspace)/results.png results_iter_$(ITER).png

          # Checking if e-mail address is present
          if [ "$(EMAIL_ADDRESS)" = "NONE" ]; then
              echo "Done iteration $(ITER) in $(MERLIN_WORKSPACE)"
          else
              echo "Done iteration $(ITER) in $(MERLIN_WORKSPACE)" | mail -s "Merlin Status for $(WORKFLOW_NAME)" -a optimization_results_iter_$(ITER).json -a results_iter_$(ITER).png $(EMAIL_ADDRESS)
          fi

          if [ $(ITER) -ge $(MAX_ITER) ] ; then
              echo "Max iterations reached"
          else
              next_iter=$(ITER)
              ((next_iter=next_iter+1))
              echo "Starting iteration " $next_iter
              merlin $(RUN_TYPE) $(MERLIN_INFO)/*partial.yaml --samplesfile $(pick_new_inputs.workspace)/new_samples.npy --vars ITER=$next_iter
          fi
        cores per task: 1
        nodes: 1
        procs: 1
        depends: [visualizer]
        task_queue: learner

merlin:
  resources:
    overlap: true
    task_server: celery
    workers:
      all_workers:
        args: -O fair --prefetch-multiplier 1 -E -l info --concurrency 20
        steps: [all]
  samples:
    column_labels:
    {% for column_label in column_labels %}
    - {{ column_label }}
    {% endfor %}
    file: $(MERLIN_INFO)/samples.npy
    generate:
      cmd: |-
          spellbook make-samples -dims $(N_DIMS) -n $(N_SAMPLES_START) -sample_type lhs -outfile=$(MERLIN_INFO)/samples.npy -scale "$(BOUNDS_X)"
